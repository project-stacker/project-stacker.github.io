{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Stacker - OCI Container Image Builder \u00b6 Stacker is a tool for building OCI images natively via a declarative yaml format. Features \u00b6 Single binary Rootless builds Hermetically sealed builds using LXC containers GitHub action Installation \u00b6 Stacker has various build and runtime dependencies. Usage \u00b6 See the tutorial for a short introduction to how to use stacker. See the stacker.yaml specification for full details on the stacker.yaml specification. Additionally, there are some tips and tricks for common usage. Hacking \u00b6 See the hacking guide for tips on hacking/debugging stacker. TODO / Roadmap \u00b6 Upstream something to containers/image that allows for automatic detection of compression Design/implement OCIv2 drafts + final spec when it comes out Conference Talks \u00b6 An Operator Centric Way to Update Application Containers FOSDEM 2019 video slides Building OCI Images without Privilege OSS EU 2018 slides Building OCI Images without Privilege OSS NA 2018 slides (Note that despite the similarity in name of the 2018 talks, the content is mostly disjoint; I need to be more creative with naming.)","title":"Home"},{"location":"#stacker-oci-container-image-builder","text":"Stacker is a tool for building OCI images natively via a declarative yaml format.","title":"Stacker - OCI Container Image Builder"},{"location":"#features","text":"Single binary Rootless builds Hermetically sealed builds using LXC containers GitHub action","title":"Features"},{"location":"#installation","text":"Stacker has various build and runtime dependencies.","title":"Installation"},{"location":"#usage","text":"See the tutorial for a short introduction to how to use stacker. See the stacker.yaml specification for full details on the stacker.yaml specification. Additionally, there are some tips and tricks for common usage.","title":"Usage"},{"location":"#hacking","text":"See the hacking guide for tips on hacking/debugging stacker.","title":"Hacking"},{"location":"#todo-roadmap","text":"Upstream something to containers/image that allows for automatic detection of compression Design/implement OCIv2 drafts + final spec when it comes out","title":"TODO / Roadmap"},{"location":"#conference-talks","text":"An Operator Centric Way to Update Application Containers FOSDEM 2019 video slides Building OCI Images without Privilege OSS EU 2018 slides Building OCI Images without Privilege OSS NA 2018 slides (Note that despite the similarity in name of the 2018 talks, the content is mostly disjoint; I need to be more creative with naming.)","title":"Conference Talks"},{"location":"hacking/","text":"Hacking stacker \u00b6 The first step to trying to find a bug in stacker is to run it with --debug. This will give you a stack trace from where (at least in stacker's code) the error originated via github.com/pkg/errors . Sometimes it is useful to write a small reproducer in test/ , and run it with: make check TEST=myreproducer.bats Overlayfs / layer issues \u00b6 Another thing --debug will show you is what overlay arguments it is sending to LXC. Note that the build overlay filesystem never exists in the host mount namespace, but is created by liblxc in the child namespace. Sometimes it can be useful to take these overlay args and split up the lowerdirs: /data/ssd/builds/stacker/stacker_layers/.roots/sha256_f8e46c301da6347e78057d8fe48a6bbd8fc0cab213d47825f5c0c0646f542b6b/overlay /data/ssd/builds/stacker/stacker_layers/.roots/sha256_7eb8e296d351fe6d0c87fea979b305e2b1f19548d99f9aee4b8030b596f02efd/overlay /data/ssd/builds/stacker/stacker_layers/.roots/sha256_ca379e914166030218007477a7b9cfd0ca3dd554c58e2401c58c634fac9182f8/overlay and look through each one (top to bottom, as the overlay stack would present) in order to see what's going on. Debugging LXC \u00b6 If things are really bad, you may end up wading through liblxc. With --debug , stacker will also try and render any liblxc ERRORs to stdout, but sometimes it can be useful to see a full liblxc trace log. This is available in $(--stacker-dir)/lxc.log for the last run. If you get even more in the weeds, you may need to build your own liblxc with debug statements. Thankfully, everything is statically linked so this is fairly easy to test locally, as long as your host liblxc can build stacker: make LXC_CLONE_URL=https://github.com/tych0/lxc LXC_BRANCH=my-debug-branch Stacker links against this through a convoluted mechanism: it builds a static C program in /cmd/lxc-wrapper/ that takes a few relevant arguments about what mode to drive liblxc in. Stacker uses the go-embed mechanism to embed the resulting statically linked binary, and then resolves and execs it at runtime via the code in /embed-exec . The reason for all this indirection vs. linking against something directly is that the kernel does not allow multithreaded programs to unshare user namespaces. Since the go runtime spawns many threads for GC and various other tasks, go code cannot directly unshare a user namespace (one wonders, then, why this was the language chosen for runc, lxd, etc...). A previous implementation (the one in lxd) was to use some __attribute__((constructor)) nonsense and hope for the best, but it doesn't work in all cases, and go-embed allows for librar-ization of stacker code if someone else wants to use it eventually. See 8fa336834f31 (\"container: move to go-embed for re-exec of C code\") for details on that approach. Overlay storage layout \u00b6 The storage parent directory is whatever is specified to stacker via --roots-dir . Each layer is extracted into a sha256_$hash/overlay directory, which is then sewn together via overlayfs. At the top level, for a layer called foo , there are two directories: foo/rootfs , and foo/overlay . During the build, foo 's rootfs is mounted inside the container as foo/rootfs , with the overlay upperdir=foo/overlay . This way, whatever filesystem mutations the foo layer's run: section performs end up in foo/overlay . After the run: section, stacker generates whatever layers the user requested from this, creates sha256_$hash/overlay dirs with the contents (if two layer types were converted, then the hash of the squashfs output will just be a symlink to the tar layer's directory to save space), and foo/overlay_metadata.json will be updated to reflect these new outputs, for use when e.g. foo is a dependency of some other layer bar . Note that there is currently one wart. In a stacker file like: foo: from: type: docker url: docker://ubuntu:latest build_only: true run: | dd if=/dev/random of=/bigfile bs=1M count=1000 bar: from: type: bult tag: foo run: | rm /bigfile The final image for bar will actually contain a layer with /bigfile in it, because the foo layer's mutations are generated independently of bar 's. Some clever userspace overlay collapsing could be done here to remove this wart, though.","title":"Hacking"},{"location":"hacking/#hacking-stacker","text":"The first step to trying to find a bug in stacker is to run it with --debug. This will give you a stack trace from where (at least in stacker's code) the error originated via github.com/pkg/errors . Sometimes it is useful to write a small reproducer in test/ , and run it with: make check TEST=myreproducer.bats","title":"Hacking stacker"},{"location":"hacking/#overlayfs-layer-issues","text":"Another thing --debug will show you is what overlay arguments it is sending to LXC. Note that the build overlay filesystem never exists in the host mount namespace, but is created by liblxc in the child namespace. Sometimes it can be useful to take these overlay args and split up the lowerdirs: /data/ssd/builds/stacker/stacker_layers/.roots/sha256_f8e46c301da6347e78057d8fe48a6bbd8fc0cab213d47825f5c0c0646f542b6b/overlay /data/ssd/builds/stacker/stacker_layers/.roots/sha256_7eb8e296d351fe6d0c87fea979b305e2b1f19548d99f9aee4b8030b596f02efd/overlay /data/ssd/builds/stacker/stacker_layers/.roots/sha256_ca379e914166030218007477a7b9cfd0ca3dd554c58e2401c58c634fac9182f8/overlay and look through each one (top to bottom, as the overlay stack would present) in order to see what's going on.","title":"Overlayfs / layer issues"},{"location":"hacking/#debugging-lxc","text":"If things are really bad, you may end up wading through liblxc. With --debug , stacker will also try and render any liblxc ERRORs to stdout, but sometimes it can be useful to see a full liblxc trace log. This is available in $(--stacker-dir)/lxc.log for the last run. If you get even more in the weeds, you may need to build your own liblxc with debug statements. Thankfully, everything is statically linked so this is fairly easy to test locally, as long as your host liblxc can build stacker: make LXC_CLONE_URL=https://github.com/tych0/lxc LXC_BRANCH=my-debug-branch Stacker links against this through a convoluted mechanism: it builds a static C program in /cmd/lxc-wrapper/ that takes a few relevant arguments about what mode to drive liblxc in. Stacker uses the go-embed mechanism to embed the resulting statically linked binary, and then resolves and execs it at runtime via the code in /embed-exec . The reason for all this indirection vs. linking against something directly is that the kernel does not allow multithreaded programs to unshare user namespaces. Since the go runtime spawns many threads for GC and various other tasks, go code cannot directly unshare a user namespace (one wonders, then, why this was the language chosen for runc, lxd, etc...). A previous implementation (the one in lxd) was to use some __attribute__((constructor)) nonsense and hope for the best, but it doesn't work in all cases, and go-embed allows for librar-ization of stacker code if someone else wants to use it eventually. See 8fa336834f31 (\"container: move to go-embed for re-exec of C code\") for details on that approach.","title":"Debugging LXC"},{"location":"hacking/#overlay-storage-layout","text":"The storage parent directory is whatever is specified to stacker via --roots-dir . Each layer is extracted into a sha256_$hash/overlay directory, which is then sewn together via overlayfs. At the top level, for a layer called foo , there are two directories: foo/rootfs , and foo/overlay . During the build, foo 's rootfs is mounted inside the container as foo/rootfs , with the overlay upperdir=foo/overlay . This way, whatever filesystem mutations the foo layer's run: section performs end up in foo/overlay . After the run: section, stacker generates whatever layers the user requested from this, creates sha256_$hash/overlay dirs with the contents (if two layer types were converted, then the hash of the squashfs output will just be a symlink to the tar layer's directory to save space), and foo/overlay_metadata.json will be updated to reflect these new outputs, for use when e.g. foo is a dependency of some other layer bar . Note that there is currently one wart. In a stacker file like: foo: from: type: docker url: docker://ubuntu:latest build_only: true run: | dd if=/dev/random of=/bigfile bs=1M count=1000 bar: from: type: bult tag: foo run: | rm /bigfile The final image for bar will actually contain a layer with /bigfile in it, because the foo layer's mutations are generated independently of bar 's. Some clever userspace overlay collapsing could be done here to remove this wart, though.","title":"Overlay storage layout"},{"location":"installation/","text":"Building and Installing Stacker \u00b6 Go Dependency \u00b6 Stacker requires at least go 1.11. Ubuntu 20.04 \u00b6 On Ubuntu 20.04 you can install Go using the instructions at: https://github.com/golang/go/wiki/Ubuntu Fedora 31 \u00b6 On Fedora 31 you can install Go with the following command: sudo dnf install golang Other Distributions \u00b6 If Go is not already packaged for your Linux distribution, you can get the latest Go version here: https://golang.org/dl/#stable Go can be installed using the instructions on on the official Go website: https://golang.org/doc/install#install Other Dependencies \u00b6 Ubuntu 20.04 \u00b6 The other build dependencies can be satisfied with the following command and packages: sudo apt install lxc-dev libacl1-dev libgpgme-dev libcap-dev libseccomp-dev sudo apt install libpam0g-dev libselinux-dev libssl-dev libzstd-dev libcryptsetup-dev libdevmapper-dev Ubuntu 22.04 \u00b6 sudo apt install lxc-dev libacl1-dev libgpgme-dev libcap-dev libseccomp-dev sudo apt install libpam0g-dev libselinux-dev libssl-dev libzstd-dev libcryptsetup-dev libdevmapper-dev cryptsetup-bin pkg-config libsquashfs1 libsquashfs-dev To run make check you will also need: sudo apt install bats jq tree umoci - https://github.com/opencontainers/umoci squashtool , but with a slightly different config than what is mentioned in the install guide (see below) - https://github.com/anuvu/squashfs Contrary to what the documentation in squashfs implies, squashtool and libsquash from squash-tools-ng need to be installed globally, as user specific path overrides aren't propagated into make check 's test envs. Thus, when you reach the step install into mylocal=\"$HOME/lib\" from the squashfs guide, use the config below. You can put them at the end of your .bashrc file so you don't need to run them every time. mylocal=\"/usr/local\" export LD_LIBRARY_PATH=$mylocal/lib${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} export PKG_CONFIG_PATH=$mylocal/lib/pkgconfig${PKG_CONFIG_PATH:+:$PKG_CONFIG_PATH} Since the path /usr/local is owned by root, when you reach the step to run make install , you need to run it as sudo . make check requires the golangci-lint binary to be present in $GOPATH/bin Since there are some tests that run with elevated privileges and use git, it will complain that the stacker folder is unsafe as it is owned by your user. To prevent that, we need to tell git to consider that folder as safe. To do this, open your git config file ( .gitconfig ) and add the following line with the path to your local stacker folder. Below is an example: [safe] directory = /home/chofnar/github/stacker Fedora 31 \u00b6 The other build dependencies can be satisfied with the following command and packages: sudo dnf install lxc-devel libcap-devel libacl-devel gpgme-devel sudo dnf install bats jq Building the Stacker Binary \u00b6 Finally, once you have the build dependencies, stacker can be built with a simple make . The stacker binary will be output as ./stacker .","title":"Installation"},{"location":"installation/#building-and-installing-stacker","text":"","title":"Building and Installing Stacker"},{"location":"installation/#go-dependency","text":"Stacker requires at least go 1.11.","title":"Go Dependency"},{"location":"installation/#ubuntu-2004","text":"On Ubuntu 20.04 you can install Go using the instructions at: https://github.com/golang/go/wiki/Ubuntu","title":"Ubuntu 20.04"},{"location":"installation/#fedora-31","text":"On Fedora 31 you can install Go with the following command: sudo dnf install golang","title":"Fedora 31"},{"location":"installation/#other-distributions","text":"If Go is not already packaged for your Linux distribution, you can get the latest Go version here: https://golang.org/dl/#stable Go can be installed using the instructions on on the official Go website: https://golang.org/doc/install#install","title":"Other Distributions"},{"location":"installation/#other-dependencies","text":"","title":"Other Dependencies"},{"location":"installation/#ubuntu-2004_1","text":"The other build dependencies can be satisfied with the following command and packages: sudo apt install lxc-dev libacl1-dev libgpgme-dev libcap-dev libseccomp-dev sudo apt install libpam0g-dev libselinux-dev libssl-dev libzstd-dev libcryptsetup-dev libdevmapper-dev","title":"Ubuntu 20.04"},{"location":"installation/#ubuntu-2204","text":"sudo apt install lxc-dev libacl1-dev libgpgme-dev libcap-dev libseccomp-dev sudo apt install libpam0g-dev libselinux-dev libssl-dev libzstd-dev libcryptsetup-dev libdevmapper-dev cryptsetup-bin pkg-config libsquashfs1 libsquashfs-dev To run make check you will also need: sudo apt install bats jq tree umoci - https://github.com/opencontainers/umoci squashtool , but with a slightly different config than what is mentioned in the install guide (see below) - https://github.com/anuvu/squashfs Contrary to what the documentation in squashfs implies, squashtool and libsquash from squash-tools-ng need to be installed globally, as user specific path overrides aren't propagated into make check 's test envs. Thus, when you reach the step install into mylocal=\"$HOME/lib\" from the squashfs guide, use the config below. You can put them at the end of your .bashrc file so you don't need to run them every time. mylocal=\"/usr/local\" export LD_LIBRARY_PATH=$mylocal/lib${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} export PKG_CONFIG_PATH=$mylocal/lib/pkgconfig${PKG_CONFIG_PATH:+:$PKG_CONFIG_PATH} Since the path /usr/local is owned by root, when you reach the step to run make install , you need to run it as sudo . make check requires the golangci-lint binary to be present in $GOPATH/bin Since there are some tests that run with elevated privileges and use git, it will complain that the stacker folder is unsafe as it is owned by your user. To prevent that, we need to tell git to consider that folder as safe. To do this, open your git config file ( .gitconfig ) and add the following line with the path to your local stacker folder. Below is an example: [safe] directory = /home/chofnar/github/stacker","title":"Ubuntu 22.04"},{"location":"installation/#fedora-31_1","text":"The other build dependencies can be satisfied with the following command and packages: sudo dnf install lxc-devel libcap-devel libacl-devel gpgme-devel sudo dnf install bats jq","title":"Fedora 31"},{"location":"installation/#building-the-stacker-binary","text":"Finally, once you have the build dependencies, stacker can be built with a simple make . The stacker binary will be output as ./stacker .","title":"Building the Stacker Binary"},{"location":"runtime/","text":"Runtime environment \u00b6 Stacker execs various tools in order to accomplish its goals. For example, in order to generate squashfs images, the mksquashfs binary needs to be present in $PATH . stacker builds things in the host's network namespace, re-exports any of HTTP_PROXY , HTTPS_PROXY , NO_PROXY and their lowercase counterparts inside the environment, and bind mounts in the host's /etc/resolv.conf. This means that the network experience inside the container should be identical to the network experience that is on the host. Since stacker is only used for building images, this is safe and most intuitive for users on corporate networks with complicated proxy and other setups. However, it does mean that packaging that expects to be able to modify things in /sys will fail, since /sys is bind mounted from the host's /sys (sysfs cannot be mounted in a network namespace that a user doesn't own). When running as an unprivileged user, stacker will attempt to run things inside a user namespace owned by the user that executed the command, and will try to map 65k user and group ids to meet the POSIX standard. This means that /etc/sub{u,g}id should be configured with enough uids to map things correctly. This configuration can be done automatically via stacker unpriv-setup . See below for discussion on unprivileged use with particular storage backends. What's inside the container \u00b6 Note that unlike other container tools, stacker generally assumes what's inside the container is a \"sane\" rootfs, i.e. it can exec sh to implement the run: section. The overlay filesystem \u00b6 Stacker cannot itself be backed by an underlying overlayfs, since stacker needs to create whiteout files, and the kernel (rightfully) forbids manual creation of whiteout files on overlay filesystems. Additionally, here are no additional userspace dependencies required to use the overlayfs backend. The overlay backend and the kernel \u00b6 For privileged use, the overlayfs backend should work on any reasonably recent kernel (say >= 4.4). For unprivileged use, the overlayfs backend requires one fairly new kernel change, a3c751a50fe6 (\"vfs: allow unprivileged whiteout creation\"). This is available in all kernels >= 5.8, and may be backported to some distribution kernels. It also requires that unprivileged users be able to mount overlay filesystems, something which is allowed in Ubuntu kernels and will be allowed in upstream kernels as of 459c7c565ac3 (\"ovl: unprivieged mounts\"), which will be released in 5.11. Stacker has checks to ensure that it can run with all these environment requirements, and will fail fast if it can't do something it should be able to do.","title":"Runtime Environment"},{"location":"runtime/#runtime-environment","text":"Stacker execs various tools in order to accomplish its goals. For example, in order to generate squashfs images, the mksquashfs binary needs to be present in $PATH . stacker builds things in the host's network namespace, re-exports any of HTTP_PROXY , HTTPS_PROXY , NO_PROXY and their lowercase counterparts inside the environment, and bind mounts in the host's /etc/resolv.conf. This means that the network experience inside the container should be identical to the network experience that is on the host. Since stacker is only used for building images, this is safe and most intuitive for users on corporate networks with complicated proxy and other setups. However, it does mean that packaging that expects to be able to modify things in /sys will fail, since /sys is bind mounted from the host's /sys (sysfs cannot be mounted in a network namespace that a user doesn't own). When running as an unprivileged user, stacker will attempt to run things inside a user namespace owned by the user that executed the command, and will try to map 65k user and group ids to meet the POSIX standard. This means that /etc/sub{u,g}id should be configured with enough uids to map things correctly. This configuration can be done automatically via stacker unpriv-setup . See below for discussion on unprivileged use with particular storage backends.","title":"Runtime environment"},{"location":"runtime/#whats-inside-the-container","text":"Note that unlike other container tools, stacker generally assumes what's inside the container is a \"sane\" rootfs, i.e. it can exec sh to implement the run: section.","title":"What's inside the container"},{"location":"runtime/#the-overlay-filesystem","text":"Stacker cannot itself be backed by an underlying overlayfs, since stacker needs to create whiteout files, and the kernel (rightfully) forbids manual creation of whiteout files on overlay filesystems. Additionally, here are no additional userspace dependencies required to use the overlayfs backend.","title":"The overlay filesystem"},{"location":"runtime/#the-overlay-backend-and-the-kernel","text":"For privileged use, the overlayfs backend should work on any reasonably recent kernel (say >= 4.4). For unprivileged use, the overlayfs backend requires one fairly new kernel change, a3c751a50fe6 (\"vfs: allow unprivileged whiteout creation\"). This is available in all kernels >= 5.8, and may be backported to some distribution kernels. It also requires that unprivileged users be able to mount overlay filesystems, something which is allowed in Ubuntu kernels and will be allowed in upstream kernels as of 459c7c565ac3 (\"ovl: unprivieged mounts\"), which will be released in 5.11. Stacker has checks to ensure that it can run with all these environment requirements, and will fail fast if it can't do something it should be able to do.","title":"The overlay backend and the kernel"},{"location":"stacker_yaml/","text":"The stacker.yaml file \u00b6 When doing a stacker build , the behavior of stacker is specified by the yaml directives below. In addition to these, stacker allows variable substitions of several forms. For example, a line like: $ONE ${{TWO}} ${{THREE:3}} When run with stacker build --substitute ONE=1 --substitute TWO=2 is processed in stacker as: 1 2 3 That is, variables of the form $FOO or ${FOO} are supported, and variables with ${FOO:default} a default value will evaluate to their default if not specified on the command line. It is an error to specify a ${FOO} style without a default; to make the default an empty string, use ${FOO:} . In addition to substitutions provided on the command line, the following variables are also available with their values from either command line flags or stacker-config file. STACKER_STACKER_DIR config name 'stacker_dir', cli flag '--stacker-dir'- STACKER_ROOTFS_DIR config name 'rootfs_dir', cli flag '--roots-dir' STACKER_OCI_DIR config name 'oci_dir', cli flag '--oci-dir' The stacker build environment will have the following environment variables available for reference: STACKER_LAYER_NAME : the name of the layer being built. STACKER_LAYER_NAME will be my-build when the run section below is executed. my-build : run : echo \"Your layer is ${STACKER_LAYER_NAME}\" from \u00b6 The from directive describes the base image that stacker will start from. It takes the form: from: type: $type url: $url tag: $tag insecure: true Some directives are irrelevant depending on the type. Supported types are: docker : url is required, insecure is optional. When insecure is specified, stacker attempts to connect via http instead of https to the Docker Hub. tar : url is required, everything else is ignored. oci : url is required, of the form path:tag . This uses the OCI image at url (which may be a local path). built : tag is required, everything else is ignored. built bases this layer on a previously specified layer in the stacker file. import \u00b6 The import directive describes what files should be made available in /stacker during the run phase. There are three forms of importing supported today: /path/to/file Will import a file or directory from the local filesystem. If the file or directory changes between stacker builds, it will be hashed and the new file will be imported on subsequent builds. http://example.com/foo.tar.gz Will import foo.tar.gz and make it available in /stacker . Note that stacker will NOT update this file unless the cache is cleared, to avoid excess network usage. That means that updates after the first time stacker downloads the file will not be reflected. stacker://$name/path/to/file Will grab /path/to/file from the previously built layer $name . import hash \u00b6 The import directive also supports specifying the hash(sha256sum) of import source, for all the three forms presented above, for example: import: - path: config.json hash: f55af805b012017bc.... - path: http://example.com/foo.tar.gz hash: b458dfd63e7883a64.... - path: stacker://$name/path/to/file hash: f805b012017bc769a.... Before copying the file it will check if the requested hash matches the actual one. stacker build supports the flag --require-flag which checks that all http(s) remote imports have an hash in all stacker YAMLs. This new import mode can be combined with the old one, for example: import: - path: \"config.json hash: \"BEEFcafeaaaaAAAA....\" - /path/to/file overlay_dirs \u00b6 This directive works only with OverlayFS backend storage. The overlay_dirs directive describes what directories (content) from the host should be available in the container's filesystem. It preserves all file/dirs attributes but no owner or group. overlay_dirs: - source: /path/to/directory dest: /usr/local/ ## optional arg, default is '/' - source: /path/to/directory2 This example will result in all the files/dirs from the host's /path/to/directory to be available under container's /usr/local/ and all the files/dirs from the host's /path/to/directory2 to be available under container's / environment , labels , working_dir , volumes , cmd , entrypoint , user \u00b6 These all correspond exactly to the similarly named bits in the OCI image config spec , and are available for users to pass things through to the runtime environment of the image. generate_labels \u00b6 The generate_labels entry is similar to run in that it contains a list of commands to run inside the generated rootfs. It runs after the run section is done, and its mutations to the filesystem are not recorded, except in one case /oci-labels . /oci-labels is a special directory where this code can write a file, and the name of the file will be the OCI label name, and the content will be the label content. build_env and build_env_passthrough \u00b6 By default, environment variables do not pass through (pollute) the build environment. build_env : this is a dictionary with environment variable definitions. their values will be present in the build's environment. build_env_passthrough : This is a list of regular expressions that work as a filter on which environment variables should be passed through from the current env into the container. To let all variables through simply set build_env_passthrough : [\".*\"] If build_env_passthrough is not set, then the default value is to allow through proxy variables HTTP_PROXY, HTTPS_PROXY, FTP_PROXY, http_proxy, https_proxy, ftp_proxy . Values in the build_env override values passed through via full_command \u00b6 Because of the odd behavior of cmd and entrypoint (and the inherited nature of these from previous stacker layers), full_command provides a way to set the full command that will be executed in the image, clearing out any previous cmd and entrypoint values that were set in the image. build_only \u00b6 build_only : indicates whether or not to include this layer in the final OCI image. This can be useful in conjunction with an import from this layer in another image, if you want to isolate the build environment for a binary but not include all of its build dependencies. binds \u00b6 binds : specifies bind mounts from the host to the container. There are two formats: binds: - /foo/bar -> /bar/baz - /zomg The first one binds /foo/bar to /bar/baz, and the second host /zomg to container /zomg. Right now there is no awareness of change for any of these bind mounts, so --no-cache should be used to re-build if the content of the bind mount has changed. config \u00b6 config key is a special type of entry in the root in the stacker.yaml file. It cannot contain a layer definition, it is used to provide configuration applicable for building all the layers defined in this file. For example, config: prerequisites: - ../folder2/stacker.yaml - ../folder3/stacker.yaml prerequisites \u00b6 If the prerequisites list is present under the config key, stacker will make sure to build all the layers in the stacker.yaml files found at the paths contained in the list. This way stacker supports building multiple stacker.yaml files in the correct order. In this particular case the parent folder of the current folder, let's call it parent , has 3 subfolders folder1 , folder2 and folder3 , each containing a stacker.yaml file. The example config above is in parent/folder1/stacker.yaml . When stacker build -f parent/folder1/stacker.yaml is invoked, stacker would search for the other two stacker.yaml files and build them first, before building the stacker.yaml specified in the command line. annotations \u00b6 annotations is a user-specified key value map that will be included in the final OCI image. Note that these annotations are included in the image manifest itself and not as part of the index.json. annotations: a.b.c.key: abc_val p.q.r.key: pqr_val While config section supports a similar labels , it is more pertitent to the image runtime. On the other hand, annotations is intended to be image-specific metadata aligned with the annotations in the image spec .","title":"YAML Reference"},{"location":"stacker_yaml/#the-stackeryaml-file","text":"When doing a stacker build , the behavior of stacker is specified by the yaml directives below. In addition to these, stacker allows variable substitions of several forms. For example, a line like: $ONE ${{TWO}} ${{THREE:3}} When run with stacker build --substitute ONE=1 --substitute TWO=2 is processed in stacker as: 1 2 3 That is, variables of the form $FOO or ${FOO} are supported, and variables with ${FOO:default} a default value will evaluate to their default if not specified on the command line. It is an error to specify a ${FOO} style without a default; to make the default an empty string, use ${FOO:} . In addition to substitutions provided on the command line, the following variables are also available with their values from either command line flags or stacker-config file. STACKER_STACKER_DIR config name 'stacker_dir', cli flag '--stacker-dir'- STACKER_ROOTFS_DIR config name 'rootfs_dir', cli flag '--roots-dir' STACKER_OCI_DIR config name 'oci_dir', cli flag '--oci-dir' The stacker build environment will have the following environment variables available for reference: STACKER_LAYER_NAME : the name of the layer being built. STACKER_LAYER_NAME will be my-build when the run section below is executed. my-build : run : echo \"Your layer is ${STACKER_LAYER_NAME}\"","title":"The stacker.yaml file"},{"location":"stacker_yaml/#from","text":"The from directive describes the base image that stacker will start from. It takes the form: from: type: $type url: $url tag: $tag insecure: true Some directives are irrelevant depending on the type. Supported types are: docker : url is required, insecure is optional. When insecure is specified, stacker attempts to connect via http instead of https to the Docker Hub. tar : url is required, everything else is ignored. oci : url is required, of the form path:tag . This uses the OCI image at url (which may be a local path). built : tag is required, everything else is ignored. built bases this layer on a previously specified layer in the stacker file.","title":"from"},{"location":"stacker_yaml/#import","text":"The import directive describes what files should be made available in /stacker during the run phase. There are three forms of importing supported today: /path/to/file Will import a file or directory from the local filesystem. If the file or directory changes between stacker builds, it will be hashed and the new file will be imported on subsequent builds. http://example.com/foo.tar.gz Will import foo.tar.gz and make it available in /stacker . Note that stacker will NOT update this file unless the cache is cleared, to avoid excess network usage. That means that updates after the first time stacker downloads the file will not be reflected. stacker://$name/path/to/file Will grab /path/to/file from the previously built layer $name .","title":"import"},{"location":"stacker_yaml/#import-hash","text":"The import directive also supports specifying the hash(sha256sum) of import source, for all the three forms presented above, for example: import: - path: config.json hash: f55af805b012017bc.... - path: http://example.com/foo.tar.gz hash: b458dfd63e7883a64.... - path: stacker://$name/path/to/file hash: f805b012017bc769a.... Before copying the file it will check if the requested hash matches the actual one. stacker build supports the flag --require-flag which checks that all http(s) remote imports have an hash in all stacker YAMLs. This new import mode can be combined with the old one, for example: import: - path: \"config.json hash: \"BEEFcafeaaaaAAAA....\" - /path/to/file","title":"import hash"},{"location":"stacker_yaml/#overlay_dirs","text":"This directive works only with OverlayFS backend storage. The overlay_dirs directive describes what directories (content) from the host should be available in the container's filesystem. It preserves all file/dirs attributes but no owner or group. overlay_dirs: - source: /path/to/directory dest: /usr/local/ ## optional arg, default is '/' - source: /path/to/directory2 This example will result in all the files/dirs from the host's /path/to/directory to be available under container's /usr/local/ and all the files/dirs from the host's /path/to/directory2 to be available under container's /","title":"overlay_dirs"},{"location":"stacker_yaml/#environment-labels-working_dir-volumes-cmd-entrypoint-user","text":"These all correspond exactly to the similarly named bits in the OCI image config spec , and are available for users to pass things through to the runtime environment of the image.","title":"environment, labels, working_dir, volumes, cmd, entrypoint, user"},{"location":"stacker_yaml/#generate_labels","text":"The generate_labels entry is similar to run in that it contains a list of commands to run inside the generated rootfs. It runs after the run section is done, and its mutations to the filesystem are not recorded, except in one case /oci-labels . /oci-labels is a special directory where this code can write a file, and the name of the file will be the OCI label name, and the content will be the label content.","title":"generate_labels"},{"location":"stacker_yaml/#build_env-and-build_env_passthrough","text":"By default, environment variables do not pass through (pollute) the build environment. build_env : this is a dictionary with environment variable definitions. their values will be present in the build's environment. build_env_passthrough : This is a list of regular expressions that work as a filter on which environment variables should be passed through from the current env into the container. To let all variables through simply set build_env_passthrough : [\".*\"] If build_env_passthrough is not set, then the default value is to allow through proxy variables HTTP_PROXY, HTTPS_PROXY, FTP_PROXY, http_proxy, https_proxy, ftp_proxy . Values in the build_env override values passed through via","title":"build_env and build_env_passthrough"},{"location":"stacker_yaml/#full_command","text":"Because of the odd behavior of cmd and entrypoint (and the inherited nature of these from previous stacker layers), full_command provides a way to set the full command that will be executed in the image, clearing out any previous cmd and entrypoint values that were set in the image.","title":"full_command"},{"location":"stacker_yaml/#build_only","text":"build_only : indicates whether or not to include this layer in the final OCI image. This can be useful in conjunction with an import from this layer in another image, if you want to isolate the build environment for a binary but not include all of its build dependencies.","title":"build_only"},{"location":"stacker_yaml/#binds","text":"binds : specifies bind mounts from the host to the container. There are two formats: binds: - /foo/bar -> /bar/baz - /zomg The first one binds /foo/bar to /bar/baz, and the second host /zomg to container /zomg. Right now there is no awareness of change for any of these bind mounts, so --no-cache should be used to re-build if the content of the bind mount has changed.","title":"binds"},{"location":"stacker_yaml/#config","text":"config key is a special type of entry in the root in the stacker.yaml file. It cannot contain a layer definition, it is used to provide configuration applicable for building all the layers defined in this file. For example, config: prerequisites: - ../folder2/stacker.yaml - ../folder3/stacker.yaml","title":"config"},{"location":"stacker_yaml/#prerequisites","text":"If the prerequisites list is present under the config key, stacker will make sure to build all the layers in the stacker.yaml files found at the paths contained in the list. This way stacker supports building multiple stacker.yaml files in the correct order. In this particular case the parent folder of the current folder, let's call it parent , has 3 subfolders folder1 , folder2 and folder3 , each containing a stacker.yaml file. The example config above is in parent/folder1/stacker.yaml . When stacker build -f parent/folder1/stacker.yaml is invoked, stacker would search for the other two stacker.yaml files and build them first, before building the stacker.yaml specified in the command line.","title":"prerequisites"},{"location":"stacker_yaml/#annotations","text":"annotations is a user-specified key value map that will be included in the final OCI image. Note that these annotations are included in the image manifest itself and not as part of the index.json. annotations: a.b.c.key: abc_val p.q.r.key: pqr_val While config section supports a similar labels , it is more pertitent to the image runtime. On the other hand, annotations is intended to be image-specific metadata aligned with the annotations in the image spec .","title":"annotations"},{"location":"tricks/","text":"Tips and Tricks \u00b6 Building a layer from scratch \u00b6 There are a couple of cases where it may be useful to build a layer from scratch. For example to derive a new base install of an OS or to build a \"tarball\" type image which just carries data and will not actually be run by a container runtime. The way to accomplish this in stacker is to use a build only layer (i.e. a layer that does not get emitted into the final OCI image, perhaps containing assets or something that will be used by the final container). The best way to accomplish this is as follows: build: from: type: docker url: docker://ubuntu:latest run: | touch /tmp/first touch /tmp/second tar -C /tmp -cv -f /contents.tar first second build_only: true contents: from: type: tar url: stacker://build/contents.tar Or e.g. to bootstrap a base layer for CentoOS 7: build: from: type: docker url: docker://ubuntu:latest run: | yum -y --installroot=/rootfs --nogpgcheck install tar -C rootfs -zcf /rootfs.tar . build_only: true contents: from: type: tar url: stacker://build/rootfs.tar These work by creating the base for the system in a build container with all the utilities available needed to manipulate that base, and then asking stacker to create a layer based on this tarball, without actually running anything inside of the layer (which means e.g. absence of a shell or libc or whatever is fine). Another way to accomplish something similar is to use a distroless layer: build: from: type: docker url: docker://ubuntu:latest binds: - /tmp/dir_to_overlay -> /dir_to_overlay run: | touch /dir_to_overlay/binaryfile build_only: true contents: from: type: docker url: docker://gcr.io/distroless/base overlay_dirs: - source: /tmp/dir_to_overlay dest: /dir_to_overlay You can use the first layer as a build env, and copy your binary to a bind-mounted folder. Use overlay_dirs with that same folder to have the binary in the distroless layer.","title":"Tips and Tricks"},{"location":"tricks/#tips-and-tricks","text":"","title":"Tips and Tricks"},{"location":"tricks/#building-a-layer-from-scratch","text":"There are a couple of cases where it may be useful to build a layer from scratch. For example to derive a new base install of an OS or to build a \"tarball\" type image which just carries data and will not actually be run by a container runtime. The way to accomplish this in stacker is to use a build only layer (i.e. a layer that does not get emitted into the final OCI image, perhaps containing assets or something that will be used by the final container). The best way to accomplish this is as follows: build: from: type: docker url: docker://ubuntu:latest run: | touch /tmp/first touch /tmp/second tar -C /tmp -cv -f /contents.tar first second build_only: true contents: from: type: tar url: stacker://build/contents.tar Or e.g. to bootstrap a base layer for CentoOS 7: build: from: type: docker url: docker://ubuntu:latest run: | yum -y --installroot=/rootfs --nogpgcheck install tar -C rootfs -zcf /rootfs.tar . build_only: true contents: from: type: tar url: stacker://build/rootfs.tar These work by creating the base for the system in a build container with all the utilities available needed to manipulate that base, and then asking stacker to create a layer based on this tarball, without actually running anything inside of the layer (which means e.g. absence of a shell or libc or whatever is fine). Another way to accomplish something similar is to use a distroless layer: build: from: type: docker url: docker://ubuntu:latest binds: - /tmp/dir_to_overlay -> /dir_to_overlay run: | touch /dir_to_overlay/binaryfile build_only: true contents: from: type: docker url: docker://gcr.io/distroless/base overlay_dirs: - source: /tmp/dir_to_overlay dest: /dir_to_overlay You can use the first layer as a build env, and copy your binary to a bind-mounted folder. Use overlay_dirs with that same folder to have the binary in the distroless layer.","title":"Building a layer from scratch"},{"location":"tutorial/","text":"Stacker Tutorial \u00b6 Stacker is a tool that allows for building OCI images in a reproducible manner, completely unprivileged. For this tutorial, we assume you have followed the installation guide and your environment satisfies all the runtime dependecies . First stacker.yaml \u00b6 The basic input to stacker is the stacker.yaml file, which describes what the base for your OCI image should be, and what to do to construct it. One of the smallest stacker files is just: first: from: type: docker url: docker://centos:latest Note the key first represents the name of the layer, and it can have any value except config , which has a special usage, see the stacker yaml documentation With this stacker file as first.yaml , we can do a basic stacker build: $ stacker build -f first.yaml building image first... importing files... Getting image source signatures Copying blob sha256:5e35d10a3ebadf9d6ab606ce72e1e77f8646b2e2ff8dd3a60d4401c3e3a76f31 69.60 MB / 69.60 MB [=====================================================] 16s Copying config sha256:44a17ce607dadfb71de41d82c75d756c2bca4db677bba99969f28de726e4411e 862 B / 862 B [============================================================] 0s Writing manifest to image destination Storing signatures unpacking to /home/ubuntu/tutorial/roots/_working running commands... generating layer... filesystem first built successfully What happened here is that stacker downloaded the centos:latest tag from the docker hub and generated it as an OCI image with tag \"first\". We can verify this: $ umoci ls --layout oci centos-latest first The centos-latest there is the OCI tag for the base image, and first is the image we generated. The next thing to note is that if we do another rebuild, less things happen: $ stacker build -f first.yaml building image first... importing files... found cached layer first Stacker will cache all of the inputs to stacker files, and only rebuild when one of them changes. The cache (and all of stacker's metadata) live in the .stacker directory where you run stacker from. Stacker's metadata can be cleaned with stacker clean , and its entire cache can be removed with stacker clean . So far, the only input is a base image, but what about if we want to import a script to run or a config file? Consider the next example: first: from: type: docker url: docker://centos:latest import: - config.json - install.sh run: | mkdir -p /etc/myapp cp /stacker/config.json /etc/myapp/ /stacker/install.sh If the content of install.sh is just echo hello world , then stacker's output will look something like: $ stacker build -f first.yaml building image first... importing files... copying config.json copying install.sh Getting image source signatures Skipping fetch of repeat blob sha256:5e35d10a3ebadf9d6ab606ce72e1e77f8646b2e2ff8dd3a60d4401c3e3a76f31 Copying config sha256:44a17ce607dadfb71de41d82c75d756c2bca4db677bba99969f28de726e4411e 862 B / 862 B [============================================================] 0s Writing manifest to image destination Storing signatures unpacking to /home/ubuntu/tutorial/roots/_working running commands... running commands for first + mkdir -p /etc/myapp + cp /stacker/config.json /etc/myapp + /stacker/install.sh hello world generating layer... filesystem first built successfully There are two new stacker file directives here: import: - config.json - install.sh Which imports those two files into the /stacker directory inside the image. This directory will not be present during the final image, so copy any files you need out of it into their final place in the image. Also, importing things from the web (via http://example.com/foo.tar.gz urls) is supported, and these things will be cached on disk. Stacker will not evaluate as long as it has a file there, so if something at the URL changes, you need to run stacker build with the --no-cache argument, or simply delete the file from .stacker/imports/$target_name/foo.tar.gz . And then there is: run: | mkdir -p /etc/myapp cp /stacker/config.json /etc/myapp/ /stacker/install.sh Which is the set of commands to run in order to install and configure the image. Also note that it used a cached version of the base layer, but then re-built the part where you asked for commands to be run, since that is new. dev/build containers \u00b6 Finally, stacker offers \"build only\" containers, which are just built, but not emitted in the final OCI image. For example: build: from: type: docker url: docker://ubuntu:latest run: | apt update apt install -y software-properties-common git apt-add-repository -y ppa:gophers/archive apt update apt install -y golang-1.9 export PATH=$PATH:/usr/lib/go-1.9/bin export GOPATH=~/go mkdir -p $GOPATH/src/github.com/openSUSE cd $GOPATH/src/github.com/openSUSE git clone https://github.com/opencontainers/umoci cd umoci make umoci.static cp umoci.static / build_only: true umoci: from: type: docker url: docker://centos:latest import: stacker://build/umoci.static run: cp /stacker/umoci.static /usr/bin/umoci Will build a static version of umoci in an ubuntu container, but the final image will only contain an umoci tag with a statically linked version of umoci at /usr/bin/umoci . There are a few new directives to support this: build_only: true indicates that the container shouldn't be emitted in the final image, because we're going to import something from it and don't need the rest of it. The line: import: stacker://build/umoci.static is what actually does this import, and it says \"from a previously built stacker image called 'build', import /umoci.static\".","title":"Tutorial"},{"location":"tutorial/#stacker-tutorial","text":"Stacker is a tool that allows for building OCI images in a reproducible manner, completely unprivileged. For this tutorial, we assume you have followed the installation guide and your environment satisfies all the runtime dependecies .","title":"Stacker Tutorial"},{"location":"tutorial/#first-stackeryaml","text":"The basic input to stacker is the stacker.yaml file, which describes what the base for your OCI image should be, and what to do to construct it. One of the smallest stacker files is just: first: from: type: docker url: docker://centos:latest Note the key first represents the name of the layer, and it can have any value except config , which has a special usage, see the stacker yaml documentation With this stacker file as first.yaml , we can do a basic stacker build: $ stacker build -f first.yaml building image first... importing files... Getting image source signatures Copying blob sha256:5e35d10a3ebadf9d6ab606ce72e1e77f8646b2e2ff8dd3a60d4401c3e3a76f31 69.60 MB / 69.60 MB [=====================================================] 16s Copying config sha256:44a17ce607dadfb71de41d82c75d756c2bca4db677bba99969f28de726e4411e 862 B / 862 B [============================================================] 0s Writing manifest to image destination Storing signatures unpacking to /home/ubuntu/tutorial/roots/_working running commands... generating layer... filesystem first built successfully What happened here is that stacker downloaded the centos:latest tag from the docker hub and generated it as an OCI image with tag \"first\". We can verify this: $ umoci ls --layout oci centos-latest first The centos-latest there is the OCI tag for the base image, and first is the image we generated. The next thing to note is that if we do another rebuild, less things happen: $ stacker build -f first.yaml building image first... importing files... found cached layer first Stacker will cache all of the inputs to stacker files, and only rebuild when one of them changes. The cache (and all of stacker's metadata) live in the .stacker directory where you run stacker from. Stacker's metadata can be cleaned with stacker clean , and its entire cache can be removed with stacker clean . So far, the only input is a base image, but what about if we want to import a script to run or a config file? Consider the next example: first: from: type: docker url: docker://centos:latest import: - config.json - install.sh run: | mkdir -p /etc/myapp cp /stacker/config.json /etc/myapp/ /stacker/install.sh If the content of install.sh is just echo hello world , then stacker's output will look something like: $ stacker build -f first.yaml building image first... importing files... copying config.json copying install.sh Getting image source signatures Skipping fetch of repeat blob sha256:5e35d10a3ebadf9d6ab606ce72e1e77f8646b2e2ff8dd3a60d4401c3e3a76f31 Copying config sha256:44a17ce607dadfb71de41d82c75d756c2bca4db677bba99969f28de726e4411e 862 B / 862 B [============================================================] 0s Writing manifest to image destination Storing signatures unpacking to /home/ubuntu/tutorial/roots/_working running commands... running commands for first + mkdir -p /etc/myapp + cp /stacker/config.json /etc/myapp + /stacker/install.sh hello world generating layer... filesystem first built successfully There are two new stacker file directives here: import: - config.json - install.sh Which imports those two files into the /stacker directory inside the image. This directory will not be present during the final image, so copy any files you need out of it into their final place in the image. Also, importing things from the web (via http://example.com/foo.tar.gz urls) is supported, and these things will be cached on disk. Stacker will not evaluate as long as it has a file there, so if something at the URL changes, you need to run stacker build with the --no-cache argument, or simply delete the file from .stacker/imports/$target_name/foo.tar.gz . And then there is: run: | mkdir -p /etc/myapp cp /stacker/config.json /etc/myapp/ /stacker/install.sh Which is the set of commands to run in order to install and configure the image. Also note that it used a cached version of the base layer, but then re-built the part where you asked for commands to be run, since that is new.","title":"First stacker.yaml"},{"location":"tutorial/#devbuild-containers","text":"Finally, stacker offers \"build only\" containers, which are just built, but not emitted in the final OCI image. For example: build: from: type: docker url: docker://ubuntu:latest run: | apt update apt install -y software-properties-common git apt-add-repository -y ppa:gophers/archive apt update apt install -y golang-1.9 export PATH=$PATH:/usr/lib/go-1.9/bin export GOPATH=~/go mkdir -p $GOPATH/src/github.com/openSUSE cd $GOPATH/src/github.com/openSUSE git clone https://github.com/opencontainers/umoci cd umoci make umoci.static cp umoci.static / build_only: true umoci: from: type: docker url: docker://centos:latest import: stacker://build/umoci.static run: cp /stacker/umoci.static /usr/bin/umoci Will build a static version of umoci in an ubuntu container, but the final image will only contain an umoci tag with a statically linked version of umoci at /usr/bin/umoci . There are a few new directives to support this: build_only: true indicates that the container shouldn't be emitted in the final image, because we're going to import something from it and don't need the rest of it. The line: import: stacker://build/umoci.static is what actually does this import, and it says \"from a previously built stacker image called 'build', import /umoci.static\".","title":"dev/build containers"}]}